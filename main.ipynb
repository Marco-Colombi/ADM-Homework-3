{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRATEGY FOR HOMEWORK 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complete alla the tasks required for the Homework 3 of ADM, we decided to split the tasks between us:\n",
    "1. **Marco Colombi** had to do the **first part**, about downloading HTML pages and find a way to scrape all the Wikipedia pages, in order to get all the needed informations and create our Database;\n",
    "2. **Mechket Ben Messaoud** had to do the **second part**, about creating the first two search engines, the vocabulary and the inverted_index, and the **fourth part**, and about finding a solution for the algorithmic question;\n",
    "3. **Omid Ghamiloo** had to do the **third part**, about finding a way to build a third search engine and implementing it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But in the end **each one of us worked also on the parts that do not belong to him/her**, helping the others to implement better ideas and writing a better code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going more on details in what we did:\n",
    "1. When we created the TSV files we decided to store all the informations in just one line where each information is separated from the other ones by '\\t' separator and we also decided to **not** take in account the **\"disambiguos\"** pages of Wikipedia;\n",
    "2. When we created the 'Filtered' TSV files, we stored the new informations by filtering only the **intro** and the **plot** and taking the other info as they are;\n",
    "3. For the Second Search Engine we decided to **not pre-computing the tf-idf** of each term in each document and store it inside a new inverted_index file, just because the creation of this new inverted_index will take a lot of time and so we decided to go for a way that computes each time the tf-idf of the words which are in the query entered by the user;\n",
    "4. In order to have the urls of all the documents in a faster way, we stored them in a **urls.json file** as a dictionary where the keys are the position of each url, and the values the urls. So when the main.py is running it will just open the urls.json file to have always ready the **Wikipedia URLS** of all the movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the idea of the **Third Search Engine** we decided to compute a **'Year-Similarity'**:\n",
    "1. We decided to allow the user to enter, not only the usual query, but also the **release year** of the film he\\she is looking for, in order to rank the movies by looking at their release date: ***more the year a film is released is closer to the one entered by the user, more its similarity is big***.\n",
    "2. To implement this idea we first found all the movies that match the usual query entered by the user, then we look for a **\"coefficient\\weight\"**: in order to compute it we first found the maximum value between the absolute value of the difference between the year entered by the user and the maximum value of the release years of the movies that match the query, and the absolute value of the difference between the year entered by the user and the minimum value of the release years of the movies that match the query. Once this value is found we just compute the coefficient\\weight by making **\"1 / the value found\"**; then we **compute the similarity** for each i-th movie that we had from the first query by computing this formula : **1 - coefficient * abs(year entered by the user - release year of the i-th movie)**. With this formula we are sure that if the two years are the same, than the similarity will be = 1 (the maximum score possible), otherwise it will have a value between 0 (included) and 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
